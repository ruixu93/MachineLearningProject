{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from hmmlearn.hmm import MultinomialHMM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "from  Preprocesscopy import Preprocesscopy\n",
    "\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = '/home/rui/Documents/MLProject/data/modified-crab/trips-in-sanfran.csv'\n",
    "city = 'san_francisco'\n",
    "tile_size = 0.360\n",
    "la_size = 0.003234\n",
    "long_size = 0.004049\n",
    "start_id = 0\n",
    "freq_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Preprocesscopy(file_path, city, tile_size, la_size, long_size, freq_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done read dataset\n",
      "done split dataset\n",
      "done find significant region\n",
      "done filter low frequency traj\n",
      "done refind significant region\n",
      "done convert train traj to region id\n",
      "done convert test traj to region id\n"
     ]
    }
   ],
   "source": [
    "data.read_dataset()\n",
    "print \"done read dataset\"\n",
    "data.split_train_test()\n",
    "print \"done split dataset\"\n",
    "data.find_significant_region(start_id)\n",
    "print \"done find significant region\"\n",
    "data.filter_low_frequency_trajectory()\n",
    "print \"done filter low frequency traj\"\n",
    "data.refind_significant_region(start_id)\n",
    "print \"done refind significant region\"\n",
    "data.convert_train_traj_to_region_id()\n",
    "print \"done convert train traj to region id\"\n",
    "data.convert_test_traj_to_region_id()\n",
    "print \"done convert test traj to region id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_train = data.taxi_train\n",
    "taxi_test = data.taxi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to convert trajactro to a numpy array\n",
    "def trace2train_format(training_data):\n",
    "    train_locations = []\n",
    "    train_lengths = []\n",
    "    for row_index, row in training_data.iterrows():\n",
    "        single_trip = row[3]\n",
    "        trip_length = len(single_trip)\n",
    "        \n",
    "        train_lengths.append(trip_length)\n",
    "        \n",
    "        for i in range(trip_length):\n",
    "            train_locations.append(single_trip[i])\n",
    "\n",
    "    train_locations = np.array(train_locations)\n",
    "    train_lengths = np.array(train_lengths)\n",
    "    return train_locations, train_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_locations, train_lengths = trace2train_format(taxi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmm1 = MultinomialHMM(n_components=16, n_iter=500, verbose=True)\n",
    "train_locations = np.column_stack([train_locations])\n",
    "hmm1.fit(train_locations, train_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hiddenmarkovmodel360-12.pkl',\n",
       " 'hiddenmarkovmodel360-12.pkl_01.npy',\n",
       " 'hiddenmarkovmodel360-12.pkl_02.npy',\n",
       " 'hiddenmarkovmodel360-12.pkl_03.npy',\n",
       " 'hiddenmarkovmodel360-12.pkl_04.npy']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.externals import joblib\n",
    "joblib.dump(hmm1, \"hiddenmarkovmodel360-12.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.load(\"hiddenmarkovmodel.pkl\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "360m  8 hidden states\n",
    "hiddenmarkovmodel360-4: 468    -5744872.8860          +0.0087\n",
    "\n",
    "\n",
    "360m  8 hidden states\n",
    "hiddenmarkovmodel360-8: 500    -5277765.4383          +3.8056\n",
    "\n",
    "360m  12 hidden states\n",
    "hiddenmarkovmodel360-12: 500    -4972390.1166          +0.2825\n",
    "\n",
    "360m  16 hidden states\n",
    "hiddenmarkovmodel360-16: 500    -4795193.7351          +2.6486\n",
    "\n",
    "360m  20 hidden states\n",
    "hiddenmarkovmodel360-20: 500    -4683460.6453          +1.8457\n",
    "\n",
    "360m  24 hidden states\n",
    "hiddenmarkovmodel360-24: 500    -4558716.5066          +0.6078"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    predictions = []\n",
    "    # parameters of hidden markov model\n",
    "    transmat = transmat_\n",
    "    emissionprob = emissionprob_\n",
    "    startprob = np.column_stack([startprob_])\n",
    "\n",
    "    # alpha recursion\n",
    "    T = len(x)\n",
    "    H = n_components\n",
    "\n",
    "    alpha = np.zeros((H, T))\n",
    "    alpha = np.asmatrix(alpha)\n",
    "    z = np.zeros(T)  # local normalisaton factors\n",
    "\n",
    "    phgh = transmat.T\n",
    "\n",
    "    alpha[:, 0] = emissionprob[:, x[0]] * startprob\n",
    "\n",
    "    z[0] = alpha[:, 0].sum()\n",
    "\n",
    "    alpha[:, 0] = alpha[:, 0] / z[0]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        predictor = phgh.dot(alpha[:, t-1])\n",
    "        alpha[:, t] = emissionprob[:, x[t]] * np.array(predictor)\n",
    "        z[t] = alpha[:, t].sum()\n",
    "        alpha[:, t] = alpha[:, t] / z[t]\n",
    "        next_hidden = phgh.dot(alpha[:, 0])\n",
    "        next_observation = emissionprob.T.dot(next_hidden)\n",
    "        next_prediction = np.where(next_observation == np.max(next_observation))\n",
    "        predictions.append(next_prediction[0][0])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
